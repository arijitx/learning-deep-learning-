{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SINGLE NODE NEURAL NETWORK - PERCEPTRON\n",
    "\n",
    "Basic Computation Unit . \n",
    "\n",
    "    1. Weights\n",
    "    2. Bias\n",
    "    3. Activation Function \n",
    "\n",
    "\n",
    "\n",
    "![perceptron](https://cdn-images-1.medium.com/max/1600/1*v88ySSMr7JLaIBjwr4chTw.jpeg)\n",
    "\n",
    "[image source](https://towardsdatascience.com/multi-layer-neural-networks-with-sigmoid-function-deep-learning-for-rookies-2-bf464f09eb7f)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE LOSS\n",
    "\n",
    "\n",
    "Basically we want to predict it correctly , so our goal will be to minimize the loss from $y $ to $y'$ \n",
    "\n",
    "We can take differnt type of loss function suitable for our problem , \n",
    "\n",
    "As example for **Regression** we can take the **Squared Loss** which is the euclidean distance between the original and predicted output or simply the $$\\large(y-y')^2$$\n",
    "\n",
    "For **Classification** we can use the **Cross Entropy Loss** \n",
    "![cross entropy](https://wikimedia.org/api/rest_v1/media/math/render/svg/1f3f3acfb5549feb520216532a40082193c05ccc)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING = Minimizing the Loss + Adjusting the Weights \n",
    "\n",
    "![training](https://raw.githubusercontent.com/arijitx/learning-deep-learning-/f14ae8fead306859238430df77140a53d6cdd2fd/Classification/imgs/perceptron_fit.gif)\n",
    "So to minimize the loss we can use a lot of techniques , the most famous among them is the **GRADIENT DESCENT**\n",
    "\n",
    "![gradient descent](https://rasbt.github.io/mlxtend/user_guide/general_concepts/gradient-optimization_files/ball.png)\n",
    "\n",
    "![grad](https://media.giphy.com/media/jUvoKxaLa7kxG/giphy.gif)\n",
    "\n",
    "\n",
    "# LETS CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (16, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.6487</td>\n",
       "      <td>4.5192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.5438</td>\n",
       "      <td>2.4443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.8990</td>\n",
       "      <td>4.2409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2.4711</td>\n",
       "      <td>5.8097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3.3590</td>\n",
       "      <td>6.4423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label       x       y\n",
       "0      1  2.6487  4.5192\n",
       "1      1  1.5438  2.4443\n",
       "2      1  1.8990  4.2409\n",
       "3      1  2.4711  5.8097\n",
       "4      1  3.3590  6.4423"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data[['x','y']].as_matrix()\n",
    "Y=data[['label']].as_matrix()\n",
    "\n",
    "p=np.random.permutation(X.shape[0])\n",
    "\n",
    "X=X[p]\n",
    "Y=Y[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the neural network / perceptron\n",
    "\n",
    "num_units=1\n",
    "num_inputs=2\n",
    "num_outputs=1\n",
    "\n",
    "#define place holder for input and output\n",
    "x=tf.placeholder(tf.float32,[None,num_inputs])\n",
    "y=tf.placeholder(tf.float32,[None,num_outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights and bias\n",
    "\n",
    "weight=tf.Variable(tf.random_normal([num_inputs,num_units]))\n",
    "bias=tf.Variable(tf.random_normal([num_units]))\n",
    "\n",
    "# activation_fns(XW +b)\n",
    "\n",
    "output=tf.add(tf.matmul(x,weight),bias)\n",
    "output=tf.sigmoid(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the cost/ loss fns and the optimizer \n",
    "\n",
    "loss=tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=y,logits=output))\n",
    "gdo=tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(loss)\n",
    "\n",
    "init=tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batch(X,Y,batch_size,idx):\n",
    "    return X[batch_size*idx:batch_size*(idx+1)],Y[batch_size*idx:batch_size*(idx+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs=20\n",
    "batch_size=20\n",
    "total_batch_count=X.shape[0]/batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch', 1, 'Loss', 0.68385118246078491)\n",
      "('Epoch', 2, 'Loss', 0.68228145837783816)\n",
      "('Epoch', 3, 'Loss', 0.68007556200027464)\n",
      "('Epoch', 4, 'Loss', 0.67680946588516244)\n",
      "('Epoch', 5, 'Loss', 0.67169371843338022)\n",
      "('Epoch', 6, 'Loss', 0.66342011690139779)\n",
      "('Epoch', 7, 'Loss', 0.65121347904205329)\n",
      "('Epoch', 8, 'Loss', 0.63864498138427739)\n",
      "('Epoch', 9, 'Loss', 0.63032569885253908)\n",
      "('Epoch', 10, 'Loss', 0.62476717233657841)\n",
      "('Epoch', 11, 'Loss', 0.6200726866722106)\n",
      "('Epoch', 12, 'Loss', 0.61579979658126827)\n",
      "('Epoch', 13, 'Loss', 0.61187458038330067)\n",
      "('Epoch', 14, 'Loss', 0.60826419591903691)\n",
      "('Epoch', 15, 'Loss', 0.60493800640106199)\n",
      "('Epoch', 16, 'Loss', 0.60186688899993901)\n",
      "('Epoch', 17, 'Loss', 0.59902412891387946)\n",
      "('Epoch', 18, 'Loss', 0.59638603925704947)\n",
      "('Epoch', 19, 'Loss', 0.59393163919448855)\n",
      "('Epoch', 20, 'Loss', 0.59164251089096065)\n",
      "[[ 0.70610118]\n",
      " [ 0.07024612]\n",
      " [ 0.531295  ]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for e in range(epochs):\n",
    "        avg_loss=0\n",
    "        for i in range(total_batch_count):\n",
    "            batch_x,batch_y=get_batch(X,Y,batch_size,i)\n",
    "            _,c=sess.run([gdo,loss],feed_dict={x:batch_x,y:batch_y})\n",
    "            avg_loss+=c/total_batch_count\n",
    "        print(\"Epoch\",e+1,'Loss',avg_loss)\n",
    "    \n",
    "    preds=output.eval({x:X[:3]})\n",
    "    print(preds)\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
