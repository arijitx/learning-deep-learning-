{
 "cells": [
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Variational Auto Encoders </h1>\n",
    "\n",
    "<h2> AutoEncoders </h2>\n",
    "\n",
    "Autoencoders are special type of encoder decoder neural network where on one side you feed your data and on the other side you want to reconstruct the same data , in the middle you try to compress the data to a vector **z** where **len(z) << len(data)** . A typical autoencoder looks like this \n",
    "\n",
    "![autoencoder](https://wiki.tum.de/download/attachments/25007151/autoencoder_structure.png?version=2&modificationDate=1485704320100&api=v2)\n",
    "![autoencoder](https://cdn-images-1.medium.com/max/703/0*yGqTBMopqHbR0fcF.)\n",
    "\n",
    "This autoencoders are good for compression of data , but not in the case when we cant to generate new data from our training images or generate data which are completely new and never seen in the training examples , but somewhere related to our training images.\n",
    "\n",
    "More formally we can define it as we want to build a generative model , which on trained on samples can learn and produce new samples which are from the training samples distribution, so our goal is to not only learn a netowork which can compress the training images and reconstruct it back but also which can learn the distribution which the training samples follow.\n",
    "\n",
    "<h2> Variational Autoencoders </h2>\n",
    "\n",
    "So in a variational autoencoder our task to is find out the distribution of our training samples and furthur produce samples from that distribution.\n",
    "\n",
    "![image](https://camo.githubusercontent.com/74620840800d49e0e3f0fb97db950212f61ec596/687474703a2f2f6b766672616e732e636f6d2f636f6e74656e742f696d616765732f323031362f30382f7661652e6a7067)\n",
    "\n",
    "Here we need to minimize two losses , One the **log liklihood loss** and the other is the **KL Divergence** , The first will ensure that we are able to reconstruct our training samples and the second ensures that we can find out the distribution of the training sample.\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "Here we use a CNN as an Encoder with layers and relu as activation and in Decoder we use Billinear Upsample. All the images are resized to 150x150.\n",
    "\n",
    "\n",
    "# Results\n",
    "\n",
    "## Reconstructions\n",
    "\n",
    "#### Epoch 28\n",
    "![recon](results/reconstruction_28.png)\n",
    "#### Epoch 20\n",
    "![recon](results/reconstruction_20.png)\n",
    "#### Epoch 10\n",
    "![recon](results/reconstruction_10.png)\n",
    "#### Epoch 2\n",
    "![recon](results/reconstruction_2.png)\n",
    "\n",
    "## Generations\n",
    "\n",
    "#### Epoch 28\n",
    "![gen](results/sample_28.png)\n",
    "#### Epoch 20\n",
    "![gen](results/sample_20.png)\n",
    "#### Epoch 10\n",
    "![gen](results/sample_10.png)\n",
    "#### Epoch 2\n",
    "![gen](results/sample_2.png)\n",
    "\n",
    "## Generation Epoch 1 to Epoch 28\n",
    "\n",
    "![gen](results/generation.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=256\n",
    "log_interval=10\n",
    "CUDA_DEVICE=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'num_workers': 1, 'pin_memory': True} \n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder('data/celebA_data',\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.CenterCrop(150),\n",
    "                       transforms.ToTensor()\n",
    "                   ])),\n",
    "                    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder('data/test_celebA',\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.CenterCrop(150),\n",
    "                       transforms.ToTensor()\n",
    "                   ])),\n",
    "                    batch_size=batch_size, shuffle=True, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 42\n"
     ]
    }
   ],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE,self).__init__()\n",
    "        self.cnv1=nn.Conv2d(3,10,3,2)\n",
    "        self.cnv2=nn.Conv2d(10,3,4,2)\n",
    "        self.fc1=nn.Linear(3*36*36,50)\n",
    "        self.fc2=nn.Linear(3*36*36,50)\n",
    "        self.fc3=nn.Linear(50,3*36*36)\n",
    "        self.up2=nn.Upsample(scale_factor=2,mode='bilinear')\n",
    "        self.pd2=nn.ReplicationPad2d(2)\n",
    "        self.uc2=nn.Conv2d(3,10,3,1)\n",
    "        self.up1=nn.Upsample(scale_factor=2,mode='bilinear')\n",
    "        self.pd1=nn.ReplicationPad2d(2)\n",
    "        self.uc1=nn.Conv2d(10,3,3,1)\n",
    "        \n",
    "        self.relu=nn.ReLU()\n",
    "        self.sigmoid=nn.Sigmoid()\n",
    "\n",
    "    \n",
    "    def encode(self,x):\n",
    "        h=self.relu(self.cnv1(x))\n",
    "        h=self.relu(self.cnv2(h))\n",
    "        h=h.view(-1,3*36*36)\n",
    "        return self.fc1(h),self.fc2(h)\n",
    "    \n",
    "    def reparameterize(self,mean,logvar):\n",
    "        if self.training:\n",
    "            std = logvar.mul(0.5).exp_()\n",
    "            eps = Variable(std.data.new(std.size()).normal_())\n",
    "            return eps.mul(std).add_(mean)\n",
    "        else:\n",
    "            return mean\n",
    "    \n",
    "    def decode(self,x):\n",
    "        x=self.fc3(x)\n",
    "        x=x.view(-1,3,36,36)\n",
    "        h=self.uc2(self.pd2(self.up2(x)))\n",
    "        h=self.uc1(self.pd1(self.up1(h)))\n",
    "        return self.sigmoid(h)\n",
    "        \n",
    "\n",
    "    def forward(self,im):\n",
    "        mu,logvar=self.encode(im)\n",
    "        z=self.reparameterize(mu,logvar)\n",
    "        return self.decode(z),mu,logvar\n",
    "    \n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    MSE = F.mse_loss(recon_x,x,size_average=False)\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    return MSE + KLD\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = Variable(data).cuda(CUDA_DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        loss = loss_function(recon_batch, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.data[0]\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader),\n",
    "                loss.data[0] / len(data)))\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / len(train_loader.dataset)))\n",
    "\n",
    "\n",
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    for i, (data, _) in enumerate(test_loader):\n",
    "        data = data.cuda(CUDA_DEVICE)\n",
    "        data = Variable(data, volatile=True)\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        test_loss += loss_function(recon_batch, data, mu, logvar).data[0]\n",
    "        if i == 0:\n",
    "            n = min(data.size(0), 8)\n",
    "            comparison = torch.cat([data[:n],recon_batch.view(batch_size, 3, 150, 150)[:n]])\n",
    "            save_image(comparison.data.cpu(),\n",
    "                     'results/reconstruction_' + str(epoch) + '.png', nrow=n)\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/169999 (0%)]\tLoss: 5952.119141\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Traceback (most recent call last):\n  File \"/home/arijitx/.local/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/arijitx/.local/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 55, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/arijitx/.local/lib/python3.5/site-packages/torchvision/datasets/folder.py\", line 122, in __getitem__\n    img = self.loader(path)\n  File \"/home/arijitx/.local/lib/python3.5/site-packages/torchvision/datasets/folder.py\", line 69, in default_loader\n    return pil_loader(path)\n  File \"/home/arijitx/.local/lib/python3.5/site-packages/torchvision/datasets/folder.py\", line 51, in pil_loader\n    with Image.open(f) as img:\n  File \"/home/arijitx/.local/lib/python3.5/site-packages/PIL/Image.py\", line 2585, in open\n    % (filename if filename else fp))\nOSError: cannot identify image file <_io.BufferedReader name='data/celebA_data/celebA/105852.jpg'>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-40f8632f80da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCUDA_DEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-da9e06842d3f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCUDA_DEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    279\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreorder_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0mnext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__next__\u001b[0m  \u001b[0;31m# Python 2 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_next_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_put_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Traceback (most recent call last):\n  File \"/home/arijitx/.local/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/arijitx/.local/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 55, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/arijitx/.local/lib/python3.5/site-packages/torchvision/datasets/folder.py\", line 122, in __getitem__\n    img = self.loader(path)\n  File \"/home/arijitx/.local/lib/python3.5/site-packages/torchvision/datasets/folder.py\", line 69, in default_loader\n    return pil_loader(path)\n  File \"/home/arijitx/.local/lib/python3.5/site-packages/torchvision/datasets/folder.py\", line 51, in pil_loader\n    with Image.open(f) as img:\n  File \"/home/arijitx/.local/lib/python3.5/site-packages/PIL/Image.py\", line 2585, in open\n    % (filename if filename else fp))\nOSError: cannot identify image file <_io.BufferedReader name='data/celebA_data/celebA/105852.jpg'>\n"
     ]
    }
   ],
   "source": [
    "model=VAE().cuda(CUDA_DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "for epoch in range(1, 50+ 1):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    sample = Variable(torch.randn(64, 50)).cuda(CUDA_DEVICE)\n",
    "    sample = model.decode(sample).cpu()\n",
    "    save_image(sample.data.view(64, 3, 150, 150),\n",
    "'results/sample_' + str(epoch) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
